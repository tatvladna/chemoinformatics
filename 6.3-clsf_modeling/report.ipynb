{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "\n",
    "# Отчет по лабораторной работе: \"Классификационное моделирование\"\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дата выполнения лабораторной работы\n",
    "\n",
    "`11.01.2025`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Название лабораторной работы \n",
    "\n",
    "`\"Классификационное моедлирование\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Цель лабораторной работы\n",
    "\n",
    "`Освоить различные методы машинного обучения для решения задачи классификации`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "\n",
    "## Задачи лабораторной работы\n",
    "\n",
    "- Создать пример использования моделей машинного обучения для задач классификации: дерево принятия решений, рандомный лес, метод ближайших соседей, логистическая регрессия.\n",
    "\n",
    "- Пропустить сбалансированные и несбалансированные данные через модели.\n",
    "\n",
    "- Сравнить результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Материалы, использовавшиеся для выполнения лабораторной работы (программы, исходные файлы ?)\n",
    "\n",
    "1. [Официальная документация RDKit](https://www.rdkit.org/docs/source/rdkit.Chem.html)\n",
    "2. [Официальная документация библиотеки scikit-learn](https://scikit-learn.org/1.5/index.html)\n",
    "* imblearn==0.0\n",
    "* matplotlib==3.9.0\n",
    "* matplotlib-inline==0.1.7\n",
    "* numpy==1.26.4\n",
    "* pandas==2.2.2\n",
    "* pandas-profiling==3.2.0\n",
    "* rdkit==2024.3.6\n",
    "* scikit-learn==1.5.1\n",
    "* seaborn==0.13.2\n",
    "* tqdm==4.66.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Поэтапное изложение процедуры\n",
    "\n",
    "1. Предобработка данных\n",
    "\n",
    "* На первом этапе данные были предобработаны с применением базового протокола стандартизации молекул. В рамках данного процесса выполнены следующие шаги:\n",
    "\n",
    "* Удаление солей.\n",
    "\n",
    "* Нейтрализация зарядов.\n",
    "\n",
    "* Приведение к родительскому фрагменту.\n",
    "\n",
    "* Приведение к стандартной таутомерной форме.\n",
    "\n",
    "* Удаление стереохимии.\n",
    "\n",
    "* Сброс изотопов (обнуление изотопного номера у атомов).\n",
    "\n",
    "* Канонизация SMILES.\n",
    "\n",
    "* Добавление и удаление водородов.\n",
    "\n",
    "* Исправление металлов.\n",
    "\n",
    "* Восстановление свойств молекулы.\n",
    "\n",
    "* Добавление стандартизированных молекул в список.\n",
    "\n",
    "* Далее из данных были удалены пропущенные значения и дубликаты.\n",
    "\n",
    "2. Извлечение дескрипторов\n",
    "\n",
    "Были извлечены основные физико-химические дескрипторы молекул:\n",
    "\n",
    "2.1 Структурные дескрипторы:\n",
    "\n",
    "* Количество тяжёлых атомов\n",
    "\n",
    "* Количество гидроксильных групп\n",
    "\n",
    "* Количество атомов азота и кислорода\n",
    "\n",
    "* Число доноров и акцепторов водорода\n",
    "\n",
    "* Количество гетероатомов\n",
    "\n",
    "* Число вращаемых связей\n",
    "\n",
    "* Общее количество валентных электронов\n",
    "\n",
    "* Количество ароматических и алифатических колец\n",
    "\n",
    "2.2 Физико-химические дескрипторы:\n",
    "\n",
    "* Молекулярная массa\n",
    "\n",
    "* Липофильность\n",
    "\n",
    "* Молекулярная рефрактивность\n",
    "\n",
    "* Топологическая полярная поверхность\n",
    "\n",
    "* Индекс Балабана\n",
    "\n",
    "3. Подготовка данных и балансировка\n",
    "\n",
    "Для обучения моделей использовались как несбалансированные, так и сбалансированные выборки. Были применены методы борьбы с несбалансированностью данных:\n",
    "\n",
    "* SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "\n",
    "* UnderSampling (уменьшение выборки)\n",
    "\n",
    "* SMOTETomek (комбинация SMOTE и удаления шумовых объектов)\n",
    "\n",
    "4. Обучение моделей\n",
    "\n",
    "Обучены следующие алгоритмы машинного обучения:\n",
    "\n",
    "* Дерево решений\n",
    "\n",
    "* Случайный лес\n",
    "\n",
    "* Метод ближайших соседей (KNN)\n",
    "\n",
    "* Логистическая регрессия\n",
    "\n",
    "5. Масштабирование признаков\n",
    "\n",
    "Перед обучением моделей были применены два метода масштабирования признаков:\n",
    "\n",
    "* MinMaxScaler\n",
    "\n",
    "* StandardScaler\n",
    "\n",
    "6. Результаты моделей\n",
    "\n",
    "Для каждой модели оценивались:\n",
    "\n",
    "* Сбалансированная точность (Balanced Accuracy)\n",
    "\n",
    "* F1-мера (F1-score)\n",
    "\n",
    "* Площадь под ROC-кривой (AUC)\n",
    "\n",
    "* Среднее время обучения (mean_time_fit_s_cv)\n",
    "\n",
    "* Среднее время предсказания (mean_time_predict_s_cv)\n",
    "\n",
    "* Размер модели (size_model_pipeline_mb)\n",
    "\n",
    "* Среднее потребление памяти (mean_ram_fit_mb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Результаты работы (+ таблицы, графики, иллюстрации?, если требуются)\n",
    "\n",
    "Масштабирование данных ни на одну модель не оказали значительного влияния.\n",
    "\n",
    "1. Дерево решений\n",
    "\n",
    "Дерево решений оказалось менее стабильным по метрикам и сильнее подвержено переобучению, особенно на несбалансированных данных.\n",
    "\n",
    "2. Случайный лес\n",
    "\n",
    "Случайный лес (Random Forest) показал наилучшие результаты по F1-score и AUC, ( особенно на локально балансированных данных и методотм балансировки SMOTE). Это делает его хорошим выбором для задач, где важно минимизировать ложные отрицания и повысить общую точность. Случайный лес требует значительно больше памяти и времени на обучение по сравнению с логистической регрессией.\n",
    "\n",
    "3. Логистическая регрессия\n",
    "\n",
    "Логистическая регрессия показала хорошие результаты после балансировки SMOTE и SMOTETomek, но уступает случайному лесу. Логистическая регрессия показала наилучший баланс между качеством предсказаний, скоростью работы и потреблением памяти.\n",
    "\n",
    "4. Метод ближайших соседей\n",
    "\n",
    "Метод ближайших соседей (KNN) также дал высокие F1-score и AUC, но страдает от высокой вычислительной сложности при больших объемах данных. KNN имеет низкое время обучения, но долгое время предсказания из-за необходимости хранения всей выборки.\n",
    "\n",
    "\n",
    "**Применение методов балансировки данных (SMOTE, UnderSampling, SMOTETomek) привело к небольшому улучшению метрик качества моделей. В частности, наблюдалось незначительное повышение значений F1-score и AUC, однако влияние балансировки оказалось менее выраженным, чем ожидалось. Это может указывать на то, что исходный дисбаланс классов не был критическим или что модели уже достаточно хорошо справлялись с исходными данными.**\n",
    "\n",
    "> ROC-кривая\n",
    "\n",
    "ROC-кривая дерева принятий решений имела только одну точку перегиба. Тогда, как у остальных, ROC-кривая имела лестничную форму. \n",
    "\n",
    "ROC-кривая строится по разным порогам вероятностей, на которых считаются True Positive Rate (TPR) и False Positive Rate (FPR).\n",
    "\n",
    "_Лестничная форма_ → означает, что у модели много различных предсказанных значений, и изменение порога постепенно изменяет TPR и FPR.\n",
    "\n",
    "*Одна точка перегиба* → возникает, если предсказания содержат очень мало уникальных вероятностей (например, всего 2 разных значения).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Выводы \n",
    "\n",
    "Если важна высокая точность и сбалансированность ошибок, стоит использовать случайный лес или KNN (при небольших объемах данных).\n",
    "Если требуется быстрое предсказание на больших данных, логистическая регрессия будет лучшим вариантом.\n",
    "Дерево решений может быть полезно для интерпретируемости, но его метрики хуже по сравнению с остальными методами.\n",
    "\n",
    "Таким образом, для оптимального результата важен компромисс между точностью, скоростью и потреблением памяти, а выбор модели зависит от специфики задачи.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
